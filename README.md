<p align="center"><img alt="a black background with white text Hello, I am Pradumna Saraf" src="https://github.com/user-attachments/assets/141347a2-5cdf-41b9-9078-4f0da3e955dc"></p>

<p align="left"> <a href="https://twitter.com/intent/follow?screen_name=pradumna_saraf" target="blank"><img src="./assets/pradumna-twitter-37k.png" height="36" alt="pradumna_saraf"/></a></p>

<div align="center">

Pradumna is a Developer Advocate, Docker Captain, and a DevOps and Go Developer. He is passionate about Open Source and has mentored hundreds of people to break into the ecosystem. He also creates content on X (formerly Twitter) and LinkedIn, educating others about Open Source and DevOps tools. Pradumna enjoys engaging with people in person and delivering talks.

</div>

### Latest Blog Post
<p align="left">
<a href="https://dev.to/pradumnasaraf/docker-can-run-llms-locally-wait-what-35fn" title="Docker Can Run LLMs Locally—Wait, What!?"><img src="./assets/Docker-model-runner.png" alt="Docker Can Run LLMs Locally—Wait, What!?" width="250px" align="left"/></a>
<a href="https://dev.to/pradumnasaraf/docker-can-run-llms-locally-wait-what-35fn" title="Docker Can Run LLMs Locally—Wait, What!?"><strong>Docker Can Run LLMs Locally—Wait, What!?</strong></a>
<div><strong>Published on: 7 April 2025</strong>
<br/>Using Docker to run Large Language Models (LLMs) locally? Yes, you heard that right. Docker is now much more than just running a container image. With Docker Model Runner, you can run and interact with LLMs locally....</p> <br/>
